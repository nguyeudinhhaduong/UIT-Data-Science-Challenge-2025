{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13118169,"sourceType":"datasetVersion","datasetId":8310039},{"sourceId":13248194,"sourceType":"datasetVersion","datasetId":8394549}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"1: Chia l√†m l√†m  c√°ch l√†m chunk overlap xong tim ƒëo·∫°n 5 ƒëo·∫°n c√≥ t·ªïng ƒëi·ªÉm cao nh·∫•t. Chunk sao cho h·∫øt c√¢u. M·ªói ƒëo·∫°n d√†i <128 token \n2: D√πng LLM ƒë·ªÉ t√¨m ra nh∆∞ng th√¥ng tin li√™n quan ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import pandas as pd \nimport re","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T08:49:33.157123Z","iopub.execute_input":"2025-09-24T08:49:33.157392Z","iopub.status.idle":"2025-09-24T08:49:36.156191Z","shell.execute_reply.started":"2025-09-24T08:49:33.157366Z","shell.execute_reply":"2025-09-24T08:49:36.15559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport torch\nimport torch.nn.functional as F\nimport pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n\ndef join_top_chunks(input_text, query_text, max_tokens=128, overlap=20, threshold=512, top_k=5, device=\"cuda\"):\n    \"\"\"\n    Tr·∫£ v·ªÅ (DataFrame top-k chunk, ƒëo·∫°n join l·∫°i t·ª´ top-k chunk).\n    \"\"\"\n\n    # ======================\n    # H√†m chia chunk theo c√¢u\n    # ======================\n    def chunk_text_by_sentence(text):\n        tokens = text.strip().split()\n        if len(tokens) <= threshold:\n            return [text.strip()]\n\n        sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n        sentence_tokens = [s.split() for s in sentences if s]\n\n        chunks, current_chunk = [], []\n        for sent in sentence_tokens:\n            if len(current_chunk) + len(sent) > max_tokens:\n                chunks.append(\" \".join(current_chunk))\n                if overlap > 0 and len(current_chunk) > overlap:\n                    current_chunk = current_chunk[-overlap:]\n                else:\n                    current_chunk = []\n            current_chunk.extend(sent)\n\n        if current_chunk:\n            chunks.append(\" \".join(current_chunk))\n        return chunks\n\n    # ======================\n    # Load model + tokenizer\n    # ======================\n    model_name = \"thanhtantran/Vietnamese_Reranker\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n    model.eval()\n\n    MAX_LENGTH = 512\n\n    # ======================\n    # Th·ª±c thi\n    # ======================\n    chunks = chunk_text_by_sentence(input_text)\n\n    # T·∫°o list query‚Äìchunk pairs\n    queries = [query_text] * len(chunks)\n\n    # Tokenize\n    inputs = tokenizer(\n        queries,\n        chunks,\n        padding=True,\n        truncation=True,\n        max_length=MAX_LENGTH,\n        return_tensors=\"pt\"\n    ).to(device)\n\n    # Inference\n    with torch.no_grad():\n        outputs = model(**inputs, return_dict=True)\n        scores = outputs.logits.view(-1).float().cpu().numpy()\n\n    # X·∫øp h·∫°ng top-k\n    top_indices = scores.argsort()[::-1][:min(top_k, len(chunks))]\n\n    top_indices = sorted(top_indices)\n\n    top_chunks = [(chunks[i], float(scores[i])) for i in top_indices]\n\n    # DataFrame\n    top_df = pd.DataFrame(top_chunks, columns=[\"chunk\", \"score\"])\n\n    # Join text\n    joined_text = \" \".join([chunks[i] for i in top_indices])\n\n    return top_df, joined_text\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm import tqdm\n\nresults = []\ndata = pd.read_csv(\"/kaggle/input/hcmus-foursight-vihallu/Vihallu/vihallu-public-test.csv\")\nfor idx, row in tqdm(data.iterrows(), total=len(data), desc=\"üîÑ Processing rows\"):\n    input_text = row[\"context\"]\n    query_text = row[\"prompt\"]\n    response_text = row[\"response\"]\n    label = row[\"predict_label\"] # N·∫øu l√† public th√¨ b·ªè \n\n    try:\n        top_df, joined_text = join_top_chunks(input_text, query_text, device=\"cuda\")\n\n        results.append({\n            \"id\": row[\"id\"],              # gi·ªØ id g·ªëc\n            \"context\": joined_text,       # thay context = joined_text\n            \"prompt\": query_text,\n            \"response\": response_text,\n            \"predict_label\" : label \n          \n        })\n    except Exception as e:\n        print(f\"‚ö†Ô∏è L·ªói ·ªü d√≤ng {idx}: {e}\")\n        results.append({\n            \"id\": row[\"id\"],\n            \"context\": input_text,                # l·ªói th√¨ context r·ªóng\n            \"prompt\": query_text,\n            \"response\": response_text,\n            \"predict_label\": label\n         \n        })\n\n# t·∫°o DataFrame k·∫øt qu·∫£\ndf_results = pd.DataFrame(results)\ndf_results.to_csv(\"vihallu_train_with_joined.csv\", index=False)\n\nprint(\"‚úÖ Done! ƒê√£ l∆∞u file vihallu_train_with_joined.csv\")\nprint(df_results.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T09:12:30.958129Z","iopub.execute_input":"2025-09-24T09:12:30.958404Z","iopub.status.idle":"2025-09-24T09:12:44.262269Z","shell.execute_reply.started":"2025-09-24T09:12:30.958383Z","shell.execute_reply":"2025-09-24T09:12:44.261304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T09:12:19.805003Z","iopub.execute_input":"2025-09-24T09:12:19.805687Z","iopub.status.idle":"2025-09-24T09:12:19.816786Z","shell.execute_reply.started":"2025-09-24T09:12:19.805641Z","shell.execute_reply":"2025-09-24T09:12:19.815889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_results.to_csv(\"Context_new.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T09:01:31.283187Z","iopub.execute_input":"2025-09-24T09:01:31.283463Z","iopub.status.idle":"2025-09-24T09:01:31.289326Z","shell.execute_reply.started":"2025-09-24T09:01:31.283446Z","shell.execute_reply":"2025-09-24T09:01:31.288631Z"}},"outputs":[],"execution_count":null}]}